# epoll的工作模式
>工作模式是什么，底层数据就绪之后，OS向上层通知的方式

**水平触发**
剩余的数据还会触发,不是因为对端发送数据过来触发的，而是因为上一次没有完全读完触发的
* epoll默认状态下就是LT工作模式，当epoll检测到socket上事件就绪的时候，可以不立即进行处理，只处理一部分，其他的等到下一次再处理

**边缘触发**
剩余的数据不会触发，而是等到下一次响应的时候才把这一次的数据发送出来
* 系统层面：通知有效次数多，并且倒逼上层将数据本次数据一次性取走
* 应用层面：并且可以将报文可以尽快成型，尽快处理

![](https://img-blog.csdnimg.cn/627f55f4aad04221b75f24ce2e8099ae.png)
>水平触发就是在水平线上疯狂触发，而边缘触发只有电位发生变化的时候才会触发
---

举例说明：
<u>如果今天别人发送了1kb的数据，缓冲区里面有1k的数据，用户定义的缓冲区有0.5k的数据</u>
**LT模式**：读取0.5Kb，或者读取一部分，由于没有读取完全，一九会在下一次epoll_wait当中获取这个事件，它还是就绪事件
**ET模式**：一定要一次性读取完1kb数据，当读取到0.5kb时（因为用户定义的缓存区里面只有0.5kb，所以还剩下的缓冲区里面装不下），需要首先处理这批数据，腾出空间继续拷贝底层的数据，因为本次；因为这一次读不完，下一次epol_wait会将这次事件不再提醒，只有下次该文件描述符又有新的事件才会再带过来，但是我们也不知下一次是什么时候

总结
ET:只有数据从无到有，从有到多，才会形成一个就绪的节点，**并且需要把文件描述符设置为非阻塞状态**
LT:数据一次性可以没有读取完，文件描述符可以设置为非阻塞也可以不设置


底层没有数据的时候就被挂起了，所以这里要用非阻塞的文件描述符（ET模式必须要这样），LT模式可以不这样，因为当数据读取上来刚好读完，下次要读取，会超过水位线才允许进程去recv


编码：
struct epoll_event的对象，event=EPOLLIN|EPOLLET;//这样就可以显示工作在ET模式下了
recv&&send都要重新封装成，封装在bucket里面，一定要循环读取，并且fd一定要非阻塞

**ET模式是否可以将文件描述符设置为阻塞**
>肯定是不行，因为ET 是边缘触发，即使用while读取也会碰到LT上面所说的问题，所以文件描述符一定要设置为非阻塞



## epoll总结和细节
* EPOLLPRI就是如果tcp当中有个紧急指针的字段，如果报文携带了，那么epoll模型就可以关注这个字段，send的时候有MSG_OOB就是带外数据，不过基本不用了
* EPOLLHUP就是文件描述符被挂断了，即对端关闭了连接
* 接续报文的内容也叫做反序列化
* 数据在inbuffer要不断消散，在数据放到外面用户定义的缓冲区里面，就可以从inbuffer里面消散了，
* function的用法就是在回调函数可以替换typedef void*（*rollback_t ）(Event&)可以换成一个function，然后后续注册方法的时候就可以使用多种可用的回调函数
* 发送除了char*

## Reactor
>本质上：就是事件就绪后调用提前注册好的方法，这个方法和具体的业务有关

解决以上问题

* 通过每个套接字配一个string outbuffer，inbuffer，来实现有输入输出缓冲区，并且通过制订协议，来保证不会出现粘包
* 每个文件描述符都要设置成非阻塞，读写的时候，即使没有读完，也会对返回值做判断重复的读
* 使用哦个reactor模式对epoll模式进行封装，就会变得特别高效

编码注意

* 由于ET模式，在读取内核数据的时候，有可能会碰到信号，此时需要继续读取，不然若没有下一次读取的话，这次读取的数据就丢失了，不仅是数据，在底层连接获取的时候，也需要重复accept，不然就会长时间得不到获取，
* listensock需要将底层连接获取上来，需要循环，而事件sock也需要设置成ET模式，然后套接字也要设置成非阻塞
* 这里用户自定义协议，用X代表两个算法的分隔